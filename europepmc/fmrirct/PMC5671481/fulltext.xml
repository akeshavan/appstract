<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN" "JATS-archivearticle1.dtd"> 
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="methods-article"><?properties open_access?><?DTDIdentifier.IdentifierValue -//NLM//DTD Journal Archiving and Interchange DTD v2.3 20070202//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName archivearticle.dtd?><?SourceDTD.Version 2.3?><?ConverterInfo.XSLTName jp2nlmx2.xsl?><?ConverterInfo.Version 1?><front><journal-meta><journal-id journal-id-type="nlm-ta">Front Neuroinform</journal-id><journal-id journal-id-type="iso-abbrev">Front Neuroinform</journal-id><journal-id journal-id-type="publisher-id">Front. Neuroinform.</journal-id><journal-title-group><journal-title>Frontiers in Neuroinformatics</journal-title></journal-title-group><issn pub-type="epub">1662-5196</issn><publisher><publisher-name>Frontiers Media S.A.</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">5671481</article-id><article-id pub-id-type="doi">10.3389/fninf.2017.00062</article-id><article-categories><subj-group subj-group-type="heading"><subject>Neuroscience</subject><subj-group><subject>Protocols</subject></subj-group></subj-group></article-categories><title-group><article-title>Semi-automated Anatomical Labeling and Inter-subject Warping of High-Density Intracranial Recording Electrodes in Electrocorticography</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Hamilton</surname><given-names>Liberty S.</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/12911/overview"/></contrib><contrib contrib-type="author"><name><surname>Chang</surname><given-names>David L.</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib><contrib contrib-type="author"><name><surname>Lee</surname><given-names>Morgan B.</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/487011/overview"/></contrib><contrib contrib-type="author"><name><surname>Chang</surname><given-names>Edward F.</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="author-notes" rid="fn001"><sup>*</sup></xref></contrib></contrib-group><aff id="aff1"><sup>1</sup><institution>Department of Neurosurgery, University of California, San Francisco</institution>, <addr-line>San Francisco, CA</addr-line>, <country>United States</country></aff><aff id="aff2"><sup>2</sup><institution>Center for Integrative Neuroscience, University of California, San Francisco</institution>, <addr-line>San Francisco, CA</addr-line>, <country>United States</country></aff><author-notes><fn fn-type="edited-by"><p>Edited by: Satrajit S. Ghosh, Massachusetts Institute of Technology, United States</p></fn><fn fn-type="edited-by"><p>Reviewed by: Andrei Irimia, University of Southern California, United States; Michael S. Beauchamp, Baylor College of Medicine, United States</p></fn><corresp id="fn001">*Correspondence: Edward F. Chang <email xlink:type="simple">edward.chang@ucsf.edu</email></corresp></author-notes><pub-date pub-type="epub"><day>31</day><month>10</month><year>2017</year></pub-date><pub-date pub-type="collection"><year>2017</year></pub-date><volume>11</volume><elocation-id>62</elocation-id><history><date date-type="received"><day>06</day><month>4</month><year>2017</year></date><date date-type="accepted"><day>05</day><month>10</month><year>2017</year></date></history><permissions><copyright-statement>Copyright &#x000a9; 2017 Hamilton, Chang, Lee and Chang.</copyright-statement><copyright-year>2017</copyright-year><copyright-holder>Hamilton, Chang, Lee and Chang</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) or licensor are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p></license></permissions><abstract><p>In this article, we introduce <monospace>img_pipe</monospace>, our open source python package for preprocessing of imaging data for use in intracranial electrocorticography (ECoG) and intracranial stereo-EEG analyses. The process of electrode localization, labeling, and warping for use in ECoG currently varies widely across laboratories, and it is usually performed with custom, lab-specific code. This python package aims to provide a standardized interface for these procedures, as well as code to plot and display results on 3D cortical surface meshes. It gives the user an easy interface to create anatomically labeled electrodes that can also be warped to an atlas brain, starting with only a preoperative T1 MRI scan and a postoperative CT scan. We describe the full capabilities of our imaging pipeline and present a step-by-step protocol for users.</p></abstract><kwd-group><kwd>intracranial recordings</kwd><kwd>electrode localization</kwd><kwd>electrocorticography</kwd><kwd>epilepsy</kwd><kwd>surgery</kwd><kwd>image coregistration</kwd><kwd>subdural electrodes</kwd><kwd>open science</kwd></kwd-group><funding-group><award-group><funding-source id="cn001">National Institutes of Health<named-content content-type="fundref-id">10.13039/100000002</named-content></funding-source><award-id rid="cn001">F32 DC014192-01</award-id><award-id rid="cn001">DP2-OD00862</award-id><award-id rid="cn001">R01-DC012379</award-id></award-group><award-group><funding-source id="cn002">Defense Advanced Research Projects Agency<named-content content-type="fundref-id">10.13039/100000185</named-content></funding-source><award-id rid="cn002">W911NF-14-2-0043</award-id></award-group></funding-group><counts><fig-count count="12"/><table-count count="1"/><equation-count count="0"/><ref-count count="22"/><page-count count="19"/><word-count count="9400"/></counts></article-meta></front><body><sec sec-type="intro" id="s1"><title>Introduction</title><p>High-density electrocorticography (ECoG) is an invasive method where recordings are obtained directly from the surface of the brain in patients with medically intractable epilepsy. This approach provides millimeter spatial and millisecond temporal resolution neurophysiological data from awake, behaving humans, which complements the information obtained from noninvasive approaches such as, fMRI, EEG, and MEG (Chang, <xref rid="B2" ref-type="bibr">2015</xref>). Preprocessing of ECoG data typically relies on aligning a preoperative MRI scan to a postoperative CT scan or postoperative MRI, then electrodes are localized either manually or in a semi-automated fashion (Kovalev et al., <xref rid="B11" ref-type="bibr">2005</xref>; Miller et al., <xref rid="B14" ref-type="bibr">2007</xref>; Dalal et al., <xref rid="B3" ref-type="bibr">2008</xref>; Hermes et al., <xref rid="B10" ref-type="bibr">2010</xref>; Oostenveld et al., <xref rid="B18" ref-type="bibr">2011</xref>; Dykstra et al., <xref rid="B6" ref-type="bibr">2012</xref>; Yang et al., <xref rid="B22" ref-type="bibr">2012</xref>; Groppe et al., <xref rid="B8" ref-type="bibr">2016</xref>; LaPlante et al., <xref rid="B12" ref-type="bibr">2016</xref>). Once electrodes are localized in the MRI, they are assigned anatomical labels, and then potentially warped to a common MNI atlas space for comparisons across subjects. While many labs that perform ECoG research have their own methods for performing these steps, to our knowledge there exists no software package that incorporates all steps of image processing necessary for ECoG electrode localization and warping from start to finish.</p><p>Here, we present a protocol to perform all of these steps, from pial surface reconstruction to CT coregistration, electrode identification and anatomical labeling, and warping to a common atlas space. We take advantage of tools provided in the nipy software package (<ext-link ext-link-type="uri" xlink:href="https://github.com/nipy/nipy/">https://github.com/nipy/nipy/</ext-link>), dural surface reconstruction from ielu (LaPlante et al., <xref rid="B12" ref-type="bibr">2016</xref>), 3D plotting in mayavi (<ext-link ext-link-type="uri" xlink:href="http://mayavi.sourceforge.net/">http://mayavi.sourceforge.net/</ext-link>; Ramachandran, <xref rid="B20" ref-type="bibr">2001</xref>), and extend on functions available in the MATLAB-based CTMR package (Hermes et al., <xref rid="B10" ref-type="bibr">2010</xref>). This protocol has been used to localize and label electrodes in our previously published work (Dichter et al., <xref rid="B5" ref-type="bibr">2016</xref>; Hamilton et al., <xref rid="B9" ref-type="bibr">2016</xref>; Leonard et al., <xref rid="B13" ref-type="bibr">2016</xref>; Moses et al., <xref rid="B15" ref-type="bibr">2016</xref>; Muller et al., <xref rid="B17" ref-type="bibr">2016b</xref>; Tang et al., <xref rid="B21" ref-type="bibr">2017</xref>). In an effort to promote open and affordable access to these tools, all requirements to run the pipeline (aside from physical hardware) are freely available for download at no cost to the user. We hope that this software will facilitate more efficient workflows within ECoG research labs and will aid in reproducibility across studies.</p></sec><sec sec-type="materials and methods" id="s2"><title>Materials and methods</title><sec><title>Subjects</title><p>Here, we present electrode localizations from human subjects undergoing surgical treatment for intractable epilepsy. Subjects were implanted with high-density subdural intracranial electrode grids (AdTech 256 channels, 4 mm center-to-center spacing and 1.17 mm diameter), subdural electrode strips (1 cm spacing), and/or depth electrodes (5 mm spacing) as part of their clinical evaluation for epilepsy surgery. This study was carried out in accordance with the recommendations of the University of California, San Francisco Institutional Review Board with written informed consent from all subjects. All subjects gave written informed consent in accordance with the Declaration of Helsinki. This protocol was approved by the University of California, San Francisco Institutional Review Board.</p></sec><sec><title>Example data</title><p>We include sample data for use with this pipeline so that the user may follow along with each of these steps and check their results. Sample data is available at <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.996813">https://doi.org/10.5281/zenodo.996813</ext-link> and includes an AC-PC aligned T1 MRI scan, CT scan, and all intermediate and final files from the execution of img_pipe. This subject's data is shown in Figure <xref ref-type="fig" rid="F1">1A</xref>. Other figures include data from this subject and others to illustrate a wide variety of scenarios that could be encountered when using our software. We suggest that users who wish to follow along download this data set, then copy the files from the acpc and CT directories to a new Freesurfer subject directory. The user can then start from the prep_recon() step. The montage and electrode device details are specified in the dataset README file and accompanying montage file.</p><fig id="F1" position="float"><label>Figure 1</label><caption><p><bold>(A)</bold> The final results of the imaging pipeline are <bold>(A)</bold> anatomically labeled surface electrodes in the subject's native space (left) and in nonlinearly warped atlas space (right) and <bold>(B)</bold> anatomically labeled depth electrodes in subject (left) and atlas (right) space. <bold>(C,D)</bold> show segmented, labeled MRI volumes from freesurfer in the native <bold>(C)</bold> and atlas <bold>(D)</bold> space, with one example electrode in the hippocampus identified in red.</p></caption><graphic xlink:href="fninf-11-00062-g0001"/></fig></sec><sec><title>Operating system requirements</title><list list-type="order"><list-item><p>Computer running Linux or Mac OS X. (Windows users should run this code on a virtual machine running Linux&#x02014;plotting code will work natively on Windows, but freesurfer will not.)</p></list-item><list-item><p>Processor speed: at least 2 GHz</p></list-item><list-item><p>RAM: 8 GB or higher recommended</p></list-item><list-item><p>Graphics card (optional): 3D graphics card and accelerated OpenGL drivers</p></list-item></list></sec><sec><title>Installation and third-party software requirements</title><p>In order to use the software described in this paper, the user will need to install the following third-party software packages:</p><list list-type="order"><list-item><p>gcc compiler (for Apple, can be downloaded through Apple Developer Command Line tools in XCode) or C++ compiler (available for Windows at <ext-link ext-link-type="uri" xlink:href="http://aka.ms/vcpython27">http://aka.ms/vcpython27</ext-link>)</p></list-item><list-item><p>Anaconda Python 2.7 or 3.5 (we recommend Anaconda python for ease of installation <ext-link ext-link-type="uri" xlink:href="https://www.continuum.io/downloads">https://www.continuum.io/downloads</ext-link>). Python 3.6 is not currently supported.</p></list-item><list-item><p>conda installer (included with Anaconda python installation)</p></list-item><list-item><p>Freesurfer (<ext-link ext-link-type="uri" xlink:href="https://surfer.nmr.mgh.harvard.edu/fswiki/DownloadAndInstall">https://surfer.nmr.mgh.harvard.edu/fswiki/DownloadAndInstall</ext-link>). Be sure to register and copy the license.txt file to the appropriate directory. If the user is running Windows, they will have to run Freesurfer through a virtual machine running Linux (see <ext-link ext-link-type="uri" xlink:href="https://surfer.nmr.mgh.harvard.edu/fswiki/Installation/FreeSurferVirtualImage">https://surfer.nmr.mgh.harvard.edu/fswiki/Installation/FreeSurferVirtualImage</ext-link>).</p></list-item><list-item><p>For warping depth electrodes, libboost C++ libraries (v1.41) (<ext-link ext-link-type="uri" xlink:href="http://www.boost.org/users/history/version_1_41_0.html">http://www.boost.org/users/history/version_1_41_0.html</ext-link>).</p></list-item><list-item><p>Optional: If using an NVIDIA graphics card, some computations can be sped up by downloading and installing the CUDA libraries (we have found that CUDA v5.5 works with Freesurfer)</p></list-item><list-item><p>For converting dicom to niftii, either use SPM12 or use dcm2nii binary (<ext-link ext-link-type="uri" xlink:href="https://www.nitrc.org/plugins/mwiki/index.php/dcm2nii:MainPage">https://www.nitrc.org/plugins/mwiki/index.php/dcm2nii:MainPage</ext-link>).</p></list-item></list><p>After installing the software above, the img_pipe module is installed by running the following commands at the terminal. We also suggest installing packages in a conda environment to avoid conflicts with any other installed software.</p><p>For Python 2.7, using conda located in your Python 2.7 installation directory:</p><preformat>
$ git clone <ext-link ext-link-type="uri" xlink:href="https://github.com/changlabucsf/img_pipe">https://github.com/changlabucsf/img_pipe</ext-link>
$ conda env create -f img_pipe/environment
&#x000a0;&#x000a0;_py27.yml
$ source activate img_pipe_py2
$ ipython
$ import img_pipe
</preformat><p>For Python 3.5, using conda located in your Python 3.5 installation directory:</p><preformat>
$ git clone <ext-link ext-link-type="uri" xlink:href="https://github.com/changlabucsf/img_pipe">https://github.com/changlabucsf/img_pipe</ext-link>
$ conda env create -f img_pipe/environment
&#x000a0;&#x000a0;_py35.yml
$ source activate img_pipe_py3
$ ipython
$ from img_pipe import img_pipe
</preformat></sec></sec><sec id="s3"><title>Results and stepwise procedures</title><sec><title>Overview of the image preprocessing and electrode localization pipeline</title><p>This paper describes how to use the <monospace>img_pipe</monospace> package, which will allow the user to take a T1 structural MRI scan and a CT scan with intracranial electrodes from the same patient, identify electrodes for visualization on the pial surface, automatically label electrodes with anatomical labels according to the Desikan-Killany atlas (Desikan et al., <xref rid="B4" ref-type="bibr">2006</xref>) and/or Destrieux atlas (Fischl et al., <xref rid="B7" ref-type="bibr">2004</xref>), and nonlinearly warp electrodes onto a common atlas brain while preserving their anatomical locations. Results of this procedure are shown in Figure <xref ref-type="fig" rid="F1">1</xref>.</p><p>The full process is described in Figure <xref ref-type="fig" rid="F2">2</xref>, which shows a flow chart of each step in this protocol.</p><fig id="F2" position="float"><label>Figure 2</label><caption><p>Flow chart schematic of imaging pipeline and use of the class img_pipe.freeCoG for electrode localization, anatomical identification, and warping.</p></caption><graphic xlink:href="fninf-11-00062-g0002"/></fig></sec><sec><title>Setting up the directory structure and paths</title><list list-type="bullet"><list-item><p>Set up the paths. If using the bash shell, edit ~<monospace>/.bashrc</monospace>, ~<monospace>/.bash_profile</monospace> to add the following lines:</p><p>&#x000a0;</p><p><monospace>$ export FREESURFER_HOME="/path/to/</monospace></p><p>&#x000a0;&#x000a0;&#x000a0;&#x000a0;<monospace>freesurfer"</monospace></p><p><monospace>$ source $FREESURFER_HOME/</monospace></p><p>&#x000a0;&#x000a0;&#x000a0;&#x000a0;<monospace>SetUpFreeSurfer.sh</monospace></p><p><monospace>$ export SUBJECTS_DIR="/path/to/</monospace></p><p>&#x000a0;&#x000a0;&#x000a0;&#x000a0;<monospace>freesurfer/subjects"</monospace></p><p><monospace>$ export</monospace></p><p>&#x000a0;&#x000a0;&#x000a0;&#x000a0;<monospace>DYLD_FALLBACK_LIBRARY_PATH="/usr/</monospace></p><p>&#x000a0;&#x000a0;&#x000a0;&#x000a0;<monospace>lib:$DYLD_LIBRARY_PATH"</monospace></p><p>For example <monospace>FREESURFER_HOME</monospace> might be <monospace>/Applications/freesurfer/</monospace> or <monospace>/usr/local/freesurfer</monospace>; <monospace>SUBJECTS_DIR</monospace> is a directory of the user's choosing but is often <monospace>/usr/local/freesurfer/subjects</monospace> or <monospace>/Applications/freesurfer/subjects</monospace>.</p></list-item><list-item><p>After adding these lines to ~<monospace>/.bashrc</monospace> or ~<monospace>/.bash_profile</monospace> and saving the file, be sure to run:</p><p><monospace>$ source ~/.bash_profile</monospace></p><p>in the terminal. This will run these commands to set the appropriate environmental variables for use by img_pipe and Freesurfer.</p></list-item><list-item><p>Running img_pipe requires a good quality, high resolution (preferably 1 mm isotropic) pre-operative T1 structural scan and a post-operative CT scan for the patient, both in nifti format. For specific requirements regarding T1 pulse sequences that work best, consult the Freesurfer beginners guide (<ext-link ext-link-type="uri" xlink:href="https://surfer.nmr.mgh.harvard.edu/fswiki/FreeSurferBeginnersGuide">https://surfer.nmr.mgh.harvard.edu/fswiki/FreeSurferBeginnersGuide</ext-link>). In general, a Siemens MPRAGE or GE SPGR sequence with excellent gray/white matter contrast will work well.</p></list-item><list-item><p>After downloading and installing the packages described above, create a new subject directory with the patient ID (for this paper, we will use the example &#x02018;test_subj&#x02019;) in the freesurfer subjects directory (for example /usr/local/freesurfer/subjects/test_subj). In a terminal, run:</p><p><monospace>$ mkdir $SUBJECTS_DIR/test_subj</monospace></p></list-item><list-item><p>In this directory, create the directories acpc and CT:</p><p><monospace>$ mkdir $SUBJECTS_DIR/test_subj/acpc</monospace></p><p><monospace>$ mkdir $SUBJECTS_DIR/test_subj/CT</monospace></p></list-item><list-item><p>Place the niftii format T1 scan in the acpc directory, and the niftii format CT scan in the CT directory. The T1 scan should be named T1_orig.nii and the CT scan should be named CT.nii.</p></list-item></list></sec><sec><title>Alignment of T1 scan to AC-PC axis</title><p>It is recommended that the user align T1 scans to the anterior commissure-posterior commissure axis before processing in Freesurfer. This will provide better initial conditions for later warping steps, and will result in the creation of meshes in a standard orientation. While some programs are able to perform this alignment automatically (e.g., the Automatic Registration Toolbox, available as a linux command line tool: <ext-link ext-link-type="uri" xlink:href="https://www.nitrc.org/projects/art">https://www.nitrc.org/projects/art</ext-link>), here we describe how to perform this process manually. Note: it is also possible to perform this alignment on the final surfaces and electrode files using Freesurfer's talairach.xfm file&#x02014;see Section Other Notes for how to do this.</p><list list-type="bullet"><list-item><p>Alignment of the T1 scan to the anterior commissure-posterior commissure axis is performed in Freeview (Figure <xref ref-type="fig" rid="F3">3</xref>). Open Freeview and load the unaligned T1 scan in the Volumes tab. To aid in axis alignment, change the cursor style &#x0201c;long&#x0201d; in Preferences <inline-graphic xlink:href="fninf-11-00062-i0001.jpg"/> Cursor style &#x0201c;Long.&#x0201d; The color may also be changed if desired.</p></list-item><list-item><p>To adjust the rotation and translation of the image, select Tools <inline-graphic xlink:href="fninf-11-00062-i0001.jpg"/> Transform Volume. Adjust the roll (with Y (P-A)) and yaw (with Z (I-S)) as necessary to make sure the head is aligned. Check the axial view to make sure the eyes show equally in the same slice (see Figure <xref ref-type="fig" rid="F3">3A</xref> vs. Figure <xref ref-type="fig" rid="F3">3B</xref>, second panel for unaligned and aligned examples). Make sure the midsagittal line is vertical in the axial view (see Figure <xref ref-type="fig" rid="F3">3A</xref> vs. Figure <xref ref-type="fig" rid="F3">3B</xref>, first and third panels) and in the coronal view. Choose Sample method &#x0201c;Cubic&#x0201d;.</p></list-item><list-item><p>Select the anterior commissure and adjust the pitch of the head so that it is in line with the posterior commissure on the horizontal axis (Figures <xref ref-type="fig" rid="F3">3A,B</xref>, last panel).</p></list-item><list-item><p>Finally, move to the (0, 0, 0) RAS coordinate (not TkReg RAS, just RAS). In the Transform Volume tool, translate the image until the cursor is at the anterior commissure.</p></list-item><list-item><p>Once the brain is in a good orientation, click &#x0201c;Save Reg&#x02026;&#x0201d; and save the transformation matrix in the acpc directory as T1_reorient.lta. Then, click &#x0201c;Save as&#x02026;&#x0201d; and save the reoriented T1 file as T1.nii in the acpc directory (e.g. /usr/local/freesurfer/subjects/test_subj/acpc).</p></list-item></list><fig id="F3" position="float"><label>Figure 3</label><caption><p><bold>(A)</bold> Unaligned T1 scan. From left to right: axial view shows vertical crosshair unaligned with longitudinal fissure, which can be corrected by adjusting yaw. Next, another axial view depicts unequal size in eyes, which can be corrected by adjusting roll. Coronal view shows vertical crosshair unaligned with longitudinal fissure, which can also be corrected by adjusting roll. Lastly, the sagittal view shows that the horizontal crosshair is not aligned with the anterior commissure (AC) and posterior commissure (PC), which can be fixed by adjusting pitch. <bold>(B)</bold> Reoriented, ACPC aligned T1 scan with corrections in yaw, roll, and pitch. From left to right: axial view shows crosshairs aligned with longitudinal fissure. Another axial view shows equal sized eyes. Next, coronal view shows vertical crosshair aligned with longitudinal fissure. Finally, sagittal view shows the anterior commissure (AC) and posterior commissure (PC) aligned on the horizontal axis. The origin (0, 0, 0) is set to the anterior commissure.</p></caption><graphic xlink:href="fninf-11-00062-g0003"/></fig></sec><sec><title>Overview of the class freeCoG</title><list list-type="bullet"><list-item><p>The img_pipe.py python module centers around the use of the class freeCoG, which is first initialized to contain information about a specific patient's data and has a number of methods that can be called to perform image coregistration, pial surface extraction, electrode anatomical labeling, and warping of electrodes into common space.</p></list-item><list-item><p>The freeCoG class contains the following attributes that should be specified during initialization:</p><list list-type="simple"><list-item><p>&#x025e6; <monospace>subj: [string]</monospace> the name of the subject ID. In this protocol, we will use <monospace>'test_subj'</monospace> as the subject ID.</p></list-item><list-item><p>&#x025e6; <monospace>hem: [string]</monospace>, <monospace>'lh', 'rh'</monospace>, or <monospace>'stereo'</monospace>. The hemisphere of implantation (can also be stereo for bilateral coverage)</p></list-item><list-item><p>&#x025e6; <monospace>zero_indexed_electrodes: [boolean, default</monospace> = <monospace>True]</monospace>, if False, will use one-indexed numbering for electrodes. This is important to note if your montage starts with electrode channel 1 vs. electrode channel 0 (since zero-indexing is the python default).</p></list-item></list></list-item><list-item><p>The following should be specified during initialization if not already in the user's path. By default they will be set to the value in the environmental variables defined previously.</p><list list-type="simple"><list-item><p><monospace>&#x025e6; subj_dir: [string]</monospace>: specify the location of the freesurfer $SUBJECTS_DIR</p></list-item><list-item><p><monospace>&#x025e6; fs_dir [string]</monospace>: the directory containing the Freesurfer executables, e.g., &#x02018;/Applications/freesurfer&#x02019;</p></list-item></list></list-item><list-item><p>The class freeCoG also contains the following methods:</p><list list-type="simple"><list-item><p><monospace>&#x025e6; prep_recon()</monospace></p><list list-type="simple"><list-item><p>&#x025a0; This method sets up the directory structure before running the Freesurfer pipeline.</p></list-item></list></list-item><list-item><p><monospace>&#x025e6; get_recon()</monospace></p><list list-type="simple"><list-item><p>&#x025a0; This method starts the Freesurfer recon-all pipeline, which takes a T1 scan and performs automatic extraction of the pial surface.</p></list-item></list></list-item><list-item><p><monospace>&#x025e6; convert_fsmesh2mlab()</monospace></p><list list-type="simple"><list-item><p>&#x025a0; This method converts the Freesurfer pial surfaces to triangle-mesh format for use/visualization in MATLAB and python.</p></list-item></list></list-item><list-item><p><monospace>&#x025e6; reg_img()</monospace></p><list list-type="simple"><list-item><p>&#x025a0; This method registers the CT to the T1 MRI.</p></list-item></list></list-item><list-item><p><monospace>&#x025e6; get_surface_warp()</monospace></p><list list-type="simple"><list-item><p>&#x025a0; This method performs the sulcal-based cortical surface warping for surface electrode warping to MNI atlas space.</p></list-item></list></list-item><list-item><p><monospace>&#x025e6; get_subcort()</monospace></p><list list-type="simple"><list-item><p>&#x025a0; This method performs automatic parcellation of the subcortical structures (from freesurfer's atlas-based parcellation), and saves them to triangle-mesh.mat files for use in MATLAB or python.</p></list-item></list></list-item><list-item><p><monospace>&#x025e6; get_cvsWarp()</monospace></p><list list-type="simple"><list-item><p>&#x025a0; This method performs a combined surface-based, volumetric, and elastic warping of single subject brains to an atlas space for accurate warping of depth electrodes into common space.</p></list-item></list></list-item><list-item><p><monospace>&#x025e6; apply_cvsWarp()</monospace></p><list list-type="simple"><list-item><p>&#x025a0; This method applies the resulting warp from get_cvsWarp() to the electrode coordinates.</p></list-item></list></list-item><list-item><p><monospace>&#x025e6; checkDepthWarps()</monospace></p><list list-type="simple"><list-item><p>&#x025a0; This method produces a PDF of each depth electrode in the subject's native space and in the common atlas space for error checking of warps.</p></list-item></list></list-item><list-item><p><monospace>&#x025e6; label_elecs()</monospace></p><list list-type="simple"><list-item><p>&#x025a0; This method automatically labels electrodes based on the freesurfer atlas parcellation.</p></list-item></list></list-item><list-item><p><monospace>&#x025e6; plot_recon_anatomy()</monospace></p><list list-type="simple"><list-item><p>&#x025a0; This method plots the anatomically labeled electrodes on a surface reconstruction.</p></list-item></list></list-item><list-item><p><monospace>&#x025e6; warp_all()</monospace></p><list list-type="simple"><list-item><p>&#x025a0; This method is a wrapper method for warping the electrodes and creating pdfs for quality checking.</p></list-item></list></list-item><list-item><p><monospace>&#x025e6; plot_brain()</monospace></p><list list-type="simple"><list-item><p>&#x025a0; This method is a wrapper function for plotting the surface reconstruction and electrodes.</p></list-item></list></list-item></list></list-item></list></sec><sec><title>Running surface reconstructions in img_pipe</title><p>Pial surface meshes are created in freesurfer, but freesurfer code is called from within img_pipe for ease of use. First we must initialize the patient object, after which we may call the appropriate methods to execute surface reconstructions.</p><sec><title>Initializing the patient in img_pipe</title><list list-type="bullet"><list-item><p>After AC-PC alignment as described above, start an ipython session and initialize the patient object. (Note: this process may be started in a Unix &#x0201c;screen&#x0201d; or &#x0201c;tmux&#x0201d; session if running on a remote server to avoid processes stopping after logout).</p><list list-type="simple"><list-item><p>&#x000bb; <monospace>import img_pipe</monospace></p></list-item><list-item><p>&#x000bb; <monospace>subj</monospace> = <monospace>'test_subj'</monospace></p></list-item><list-item><p>&#x000bb; <monospace>hem</monospace> = <monospace>'rh'</monospace></p></list-item><list-item><p>&#x000bb; <monospace>patient</monospace> = <monospace>img_pipe.freeCoG(subj</monospace> = <monospace>subj, hem</monospace> = <monospace>hem)</monospace></p></list-item></list></list-item></list></sec><sec><title>Creating pial surface reconstructions in freesurfer</title><list list-type="bullet"><list-item><p>Next, prepare the directory structure for running Freesurfer by running the following command in an ipython session:</p><list list-type="simple"><list-item><p>&#x000bb; <monospace>patient.prep_recon()</monospace></p></list-item></list></list-item></list><p>This will create the directories <monospace>elecs, mri</monospace>, and <monospace>mri/orig</monospace>, and will copy the acpc-aligned <monospace>T1.nii</monospace> to <monospace>mri/orig</monospace> and convert it to Freesurfer mgz format.</p><list list-type="bullet"><list-item><p>Next, run the following step, which will call freesurfer's recon-all script.</p><list list-type="simple"><list-item><p>&#x000bb; <monospace>patient.get_recon()</monospace></p></list-item></list></list-item></list><p>This will create the directories <monospace>bem, label, mri, scripts, src, stats</monospace>, <monospace>surf, tmp, touch</monospace>, and <monospace>trash</monospace> and will run through the entire Freesurfer pipeline, which will produce a skull-stripped MRI, left and right hemisphere pial surfaces (as well as white matter and inflated surfaces), and anatomical labels for the surface and MRI files. More information on this process is provided in the Freesurfer documentation (<ext-link ext-link-type="uri" xlink:href="https://surfer.nmr.mgh.harvard.edu/fswiki">https://surfer.nmr.mgh.harvard.edu/fswiki</ext-link>) and is not discussed here.</p><list list-type="bullet"><list-item><p>The Freesurfer pial surfaces will be in the surf directory (<monospace>surf/lh.pial</monospace> for left hemisphere, <monospace>surf/rh.pial</monospace> for right hemisphere), and the skull-stripped MRI will be in <monospace>mri/brain.mgz</monospace></p></list-item><list-item><p><bold>Pause point:</bold> Check the pial surfaces in freeview (Figure <xref ref-type="fig" rid="F4">4</xref>) to assure that there is good correspondence between the pial surface and the gray/CSF boundary. To check the pial surfaces, call <monospace>patient.check_pial()</monospace>, which will open a Freeview window with the MRI and pial surface loaded. Scroll through the slices and check whether the pial surface accurately corresponds to the MRI. Figure <xref ref-type="fig" rid="F4">4A</xref> shows an example of a poor correspondence in the temporal lobe due to anatomical lesion &#x02013; this pial surface would need to be corrected using edits to the white matter surface (<ext-link ext-link-type="uri" xlink:href="https://surfer.nmr.mgh.harvard.edu/fswiki/FsTutorial/WhiteMatterEdits_freeview">https://surfer.nmr.mgh.harvard.edu/fswiki/FsTutorial/WhiteMatterEdits_freeview</ext-link>). Figure <xref ref-type="fig" rid="F4">4B</xref> shows good correspondence between the pial surface (yellow) and the underlying MRI. Figure <xref ref-type="fig" rid="F4">4C</xref> shows how this surface appears in the 3D view. Given a high quality T1 scan with minimal motion, the user should be able to extract a good quality pial surface that looks relatively smooth (without spiky artifacts) and that follows the underlying anatomy.</p></list-item><list-item><p><bold>Note for those running code on a cluster:</bold> The user may change the call to recon-all in get_recon() to use a queue submission procedure of choice. For example, the call to recon-all can be specified in a &#x02018;qsub&#x02019; command to send the command to an SGE cluster computing system.</p></list-item></list><fig id="F4" position="float"><label>Figure 4</label><caption><p>Pial surfaces identified by freesurfer during get_recon() are used to create a triangle-vertex mesh. <bold>(A)</bold> Example of an incorrect pial surface outline generated by freesurfer&#x02014;these must be corrected by manually editing the white matter mask in freeview (see <ext-link ext-link-type="uri" xlink:href="https://surfer.nmr.mgh.harvard.edu/fswiki/FsTutorial/WhiteMatterEdits_freeview">https://surfer.nmr.mgh.harvard.edu/fswiki/FsTutorial/WhiteMatterEdits_freeview</ext-link> for details). <bold>(B)</bold> Example of correctly outlined pial surface outline. <bold>(C)</bold> The 3D mesh generated from the pial surface from <bold>(B)</bold>.</p></caption><graphic xlink:href="fninf-11-00062-g0004"/></fig></sec><sec><title>Converting freesurfer meshes to triangle/vertex meshes for use in MATLAB/Python</title><list list-type="bullet"><list-item><p>The <monospace>lh.pial</monospace> and <monospace>rh.pial</monospace> surfaces in freesurfer contain the data for plotting a triangle/vertex mesh, which can be used later in any 3D program (for example mayavi in python, Blender, Unity, or MATLAB).</p></list-item><list-item><p>To convert the freesurfer format to arrays of vertex coordinates (in surface RAS) and triangle indices, call the following method. By default, this will create the pial surfaces for both the left and right hemisphere.</p><list list-type="simple"><list-item><p>&#x000bb; <monospace>patient.convert_fsmesh2mlab()</monospace></p></list-item></list></list-item><list-item><p>This method can also be called with the optional keyword argument, which can also convert <monospace>lh.white, rh.white, lh.inflated</monospace>, and <monospace>rh.inflated</monospace> to triangle/vertex files.</p><list list-type="simple"><list-item><p>&#x000bb; <monospace>patient.convert_fsmesh2mlab(mesh_name</monospace> = <monospace>'inflated')</monospace></p></list-item></list></list-item><list-item><p>The surface meshes created will be available as the mat files <monospace>/your/Freesurfer/subjects_dir/test_subj/</monospace>
<monospace>Meshes/lh_pial_trivert.mat</monospace> and <monospace>/your/Free</monospace>
<monospace>surfer/subjects_dir/test_subj/</monospace>
<monospace>Meshes/ rh_pial_trivert.mat</monospace>, can now be plotted with the following command, which plots the pial meshes of both hemispheres:</p><list list-type="simple"><list-item><p>&#x000bb; <monospace>patient.plot_brain()</monospace></p></list-item></list></list-item></list></sec><sec><title>Creation of subcortical meshes</title><list list-type="bullet"><list-item><p>In addition to the cortical pial surface meshes, the user can create surface meshes for the subcortical structures identified in freesurfer. These surface meshes are created using a script created by Anderson M. Winkler (<ext-link ext-link-type="uri" xlink:href="http://brainder.org">http://brainder.org</ext-link>), which takes freesurfer labels (e.g., the voxels labeled as hippocampus, Figure <xref ref-type="fig" rid="F5">5A</xref>), and creates a 3D triangle mesh from these labels (Figure <xref ref-type="fig" rid="F5">5B</xref>). This method will create meshes for all subcortical structures labeled in Freesurfer (Figure <xref ref-type="fig" rid="F5">5C</xref>), including the left and right nucleus accumbens, amygdala, brain stem, caudate nucleus, ventricles (lateral, inferior lateral, third, and fourth), globus pallidus, hippocampus, putamen, thalamus, and ventral diencephalon.</p><list list-type="simple"><list-item><p>&#x000bb; <monospace>patient.get_subcort()</monospace></p></list-item></list></list-item></list><list list-type="bullet"><list-item><p>The meshes will be stored in the subjects directory within Meshes/subcortical/. These meshes can also now be viewed with the following commands:</p><p><monospace>&#x0003e;&#x0003e;&#x0003e; subcort_roi = patient.roi</monospace></p><p><monospace>&#x000a0;(name='your_subcortical_roi')</monospace></p><p><monospace>&#x0003e;&#x0003e;&#x0003e; patient.plot_brain(rois=[subcort_roi])</monospace></p></list-item></list><list list-type="bullet"><list-item><p>To show these ROIs in conjunction with the pial surface, they can be plotted simultaneously, while controlling color and opacity.</p><p><monospace>&#x0003e;&#x0003e;&#x0003e; subcort_roi = patient.roi (name =</monospace></p><p><monospace>&#x000a0;'your_subcortical_roi', color=(1.0, 0.0,</monospace></p><p><monospace>&#x000a0;&#x000a0;&#x000a0;&#x000a0;0.0))</monospace></p><p><monospace>&#x0003e;&#x0003e;&#x0003e; pial_roi = patient.roi (name =</monospace></p><p><monospace>&#x000a0;'lh_pial', opacity=0.5)</monospace></p><p><monospace>&#x0003e;&#x0003e;&#x0003e; patient.plot_brain(rois=[pial_roi,</monospace></p><p><monospace>&#x000a0;subcort_roi])</monospace></p></list-item></list><fig id="F5" position="float"><label>Figure 5</label><caption><p>Subcortical mesh generation. <bold>(A)</bold> Subcortical meshes are generated from parcellating the aseg.mgz file, which assigns a numeric value to each region of interest. Labels of interest are extracted from the aseg volume, and a marching cubes algorithm is run to generate a surface mesh. In this case, the volume label for the hippocampus (yellow, number value = 17) is shown in yellow. <bold>(B)</bold> The resulting 3D hippocampal mesh after marching cubes, shown with a bisecting coronal slice of the medial temporal lobe. <bold>(C)</bold> Subcortical meshes on the template brain, cvs_avg35_inMNI152. 23 subcortical meshes in the left and right hemisphere cortical meshes are shown. Subcortical meshes are colored to match the FreeSurferColorLUT (look up table).</p></caption><graphic xlink:href="fninf-11-00062-g0005"/></fig></sec></sec><sec><title>Co-registration of CT and MRI scans</title><p>In order to identify electrodes on the pial surface, we must transform the posteroperative CT scan into the same space as the T1 MRI. We use the normalized mutual information cost function (Ashburner and Friston, <xref rid="B1" ref-type="bibr">1997</xref>) to perform this cross-modal registration in nipy.</p><list list-type="simple"><list-item><p>&#x000bb; <monospace>patient.reg_img()</monospace></p><list list-type="simple"><list-item><p>&#x025e6; The user may also choose to specify the CT and MRI scans to align explicitly, using keyword arguments, though this is not necessary if the directory structure is set up as described. The CT scan is assumed to be in the CT directory, and the MRI scan is assumed to be in the mri directory.</p></list-item></list><list list-type="simple"><list-item><p>&#x000bb; <monospace>patient.reg_img(source</monospace>=<monospace>'CT.nii'</monospace>,</p><p><monospace>&#x000a0;&#x000a0;target</monospace>=<monospace>'orig.mgz')</monospace></p></list-item></list></list-item></list><list list-type="bullet"><list-item><p>Check the coregistration of the CT and MRI in freeview (Figure <xref ref-type="fig" rid="F6">6A</xref>). One way to do this is to load the CT on top of the MRI in the Volumes tab, then decrease the opacity of the CT to inspect the alignment of the bones in the skull. We recommend using the &#x02018;heat&#x02019; colormap for the CT and grayscale for the MRI. Check sagittal, coronal, and axial views to ensure that the bones of the skull are aligned properly in both images. When plotting the maximum intensity projection of the CT (Figure <xref ref-type="fig" rid="F6">6B</xref>), the user should also verify that the grids and strips are in roughly the right place.</p></list-item><list-item><p><bold>Note:</bold> It is common that when the CT is aligned to the pre-op MRI, lateral grids may appear as though they are underneath the brain's surface. This is common because the placement of these grids results in a deformation of the brain surface (Hermes et al., <xref rid="B10" ref-type="bibr">2010</xref>). We solve this by later projecting these electrodes to the pial surface.</p></list-item><list-item><p><bold>Quality check step:</bold> If the CT alignment fails, the user may need to change the initial alignment of the CT scan. Often, poor registrations can be traced back to poor initial conditions [T1 is not aligned to the AC-PC, or the CT scan's original position is at a very different orientation from the desired registered output (Figure <xref ref-type="fig" rid="F6">6C</xref>)]. The user may need to manually align the CT for an initial placement, then rerun the coregistration to get a precise alignment between CT and MRI). This can be done in freeview, SPM, or other neuroimaging programs.</p></list-item></list><fig id="F6" position="float"><label>Figure 6</label><caption><p><bold>(A)</bold> Transverse view in Freeview of a CT and an MRI that have been co-registered- the electrodes are the orange points in the left hemisphere. Note how the skull in both the CT and MRI are aligned after registration. <bold>(B)</bold> An intensity projection view. <bold>(C)</bold> CT and T1 scan in original native space before alignment. The CT shown here (in &#x0201c;heat&#x0201d; colormap) was unable to be aligned to the T1 scan (grayscale image) because of poor initial conditions. To align, the CT was translated and rotated to be in rough alignment with the T1 scan, and then reregistered in img_pipe.</p></caption><graphic xlink:href="fninf-11-00062-g0006"/></fig></sec><sec><title>Manual identification of electrodes</title><p>While other methods have been developed to automatically determine the 3D spatial location of electrodes in a CT scan (LaPlante et al., <xref rid="B12" ref-type="bibr">2016</xref>), in practice it is often difficult to fully automate the process given the limited resolution of most clinical CT scans, especially for high-density grids with &#x0003c;=4 mm spacing often employed in our research (Chang, <xref rid="B2" ref-type="bibr">2015</xref>; Muller et al., <xref rid="B16" ref-type="bibr">2016a</xref>,<xref rid="B17" ref-type="bibr">b</xref>). Here we describe the process for manually identifying electrodes that will later be automatically labeled according to their nearest anatomical location (based on Freesurfer atlas segmentation). This step also ensures that electrode numbering will match the clinical or research montage for ease of future analysis.</p><sec><title>Electrode identification on the co-registered CT scan</title><list list-type="bullet"><list-item><p>Electrodes will be identified in the postoperative, co-registered CT scan using an electrode picker GUI (Figure <xref ref-type="fig" rid="F7">7</xref>). The coordinates obtained can be used to plot the electrodes on the meshes (Figure <xref ref-type="fig" rid="F7">7A</xref>, top right). To start the electrode identification process, call <monospace>patient.mark_electrodes()</monospace>. This will launch an interactive python GUI that will overlay the registered CT scan on top of the skull-stripped MRI. Instructions for use are detailed below. The user can also press &#x02018;h&#x02019; (for help) while in the GUI for a list of possible commands.</p></list-item><list-item><p>Click to navigate the crosshairs to electrode 1 of a device (a strip, depth, or grid). Numbering for depths and strips is usually distal to proximal. Intraoperative photos can be useful to verify the numbering of grids. It can also be useful to view the CT intensity projection map (bottom right subplot in the GUI, shown in Figures <xref ref-type="fig" rid="F7">7A,B</xref>) to get a sense of the arrangement of the electrodes.</p></list-item><list-item><p>Add a new device by pressing the &#x02018;n&#x02019; key. This will prompt the user to enter the device name in the python console (this may be behind the figure window). If marking corners of a high density grid, this could be called &#x02018;hd_grid_corners&#x02019;. If marking a hippocampal depth, this could be called &#x02018;hippocampal_depth&#x02019;. Another good heuristic is to use the labels from a provided clinical electrode montage.</p></list-item><list-item><p>Ensure that the crosshairs are in the center of the electrode artifact in the coronal, axial and sagittal views. <bold>Tip:</bold> When clicking on an electrode, the user can quickly identify the correct placement in all views by clicking on an electrode in, for example, the coronal view, then zooming in to the CT scan (on a Mac, using the scroll wheel), which will re-center the other image views with the marked electrode in the center.</p></list-item><list-item><p>Click &#x02018;e&#x02019; to add an electrode at the crosshair position. The user should now see a colored circle in all views (sagittal, axial, and coronal) for this electrode, and a legend showing the device name will appear in the maximum intensity projection plot. Electrodes will automatically be saved to the variable &#x02018;elecmatrix&#x02019; in a file in the elecs directory, which will be named according to the device name given by the user. Add multiple electrodes to the same device by pressing &#x02018;e&#x02019; for each. To start adding to a new device, simply press &#x02018;n&#x02019; to initialize a new device and enter the name into the python console and start the process as before.</p></list-item><list-item><p>While marking electrodes, the user can zoom in and out on the plot using the mouse scroll wheel or trackpad scroll, pan with the arrow keys, and move through single slices using the &#x0201c;page up&#x0201d; and &#x0201c;page down&#x0201d; keys. They can also simply click on any of the views to move to that location in the CT and MRI.</p></list-item><list-item><p>To change the plot view of the maximum intensity projection, choose &#x02018;s&#x02019; for sagittal (the default), &#x02018;c&#x02019; for coronal, or &#x02018;a&#x02019; for axial. The maximum intensity projection is calculated for the current slice &#x000b1; 15 slices, so it may be useful to scroll through this plot as well.</p></list-item><list-item><p>The outline of the pial surface is plotted in yellow for reference. Toggle this on and off using the &#x02018;t&#x02019; key.</p></list-item><list-item><p>It can be helpful to plot elecmatrix on the 3D brain to check the placement of the grids and depths. To inspect a 3D visualization of the currently identified electrodes, press the number &#x02018;3&#x02019; key. Simply close the 3D window to continue marking electrodes.</p></list-item><list-item><p>The pial surface is created from a preoperative MRI, and postoperative brain shift can cause strips and grids in rCT.nii to appear buried within the pial surface. This shift is most noticeable in lateral grids, and can be corrected using a mean normal projection, described below. For some strips this shift is less pronounced and can be corrected manually during the electrode identification process in the electrode picker or Freeview. With <monospace>lh.pial</monospace> or <monospace>rh.pial</monospace> displayed on top of rCT, pick a coordinate near the electrode that places it on the surface of the brain. Plotting elecmatrix on the brain during this manual projection can ensure the coordinate is on the surface and looks appropriate with respect to the rest of the device.</p></list-item></list><fig id="F7" position="float"><label>Figure 7</label><caption><p>Example of identification of electrode coordinates using electrode picker. <bold>(A)</bold> Demonstrates the process of picking the coordinate for the most posterior inferior grid corner. On the left, the GUI is shown with the electrode selected. The pial surface, rCT, and skull stripped MRI are displayed. The upper left shows the electrode selected in the sagittal view. The upper right shows the coronal view. The bottom left shows an axial view. The lower right displays the intensity projection map of the CT, which is useful for visualizing the entire grid. To save the coordinate, press &#x0201c;n&#x0201d; to name a new device. With the center of the electrode artifact localized by the crosshairs in the axial, sagittal, and coronal views, press &#x0201c;e&#x0201d; to add a point. The coordinates are automatically saved to the &#x0201c;elecs&#x0201d; folder. The location of these points in 3D can be viewed by launching a separate 3D viewer by pressing &#x0201c;3.&#x0201d; This plot can be seen in the right panel. If the coordinates appear buried in the Mesh due to post-operative brain shift, additional steps can be taken to project the electrode to the surface, shown in Figure <xref ref-type="fig" rid="F8">8</xref>. <bold>(B)</bold> Example of identification of an electrode that is part of a subtemporal strip. The strip can be seen in the rCT.nii intensity projection map in the lower right panel. The coordinate is recorded from the center of the electrode artifact, seen in sagittal, coronal, and axial views. This coordinate can then be visualized on the 3D surface mesh, seen in the right panel, by typing &#x0201c;3.&#x0201d;</p></caption><graphic xlink:href="fninf-11-00062-g0007"/></fig></sec><sec><title>Grid interpolation for high-density ECoG grids</title><list list-type="bullet"><list-item><p>When using high-density (&#x0003c;=4 mm center-to-center spacing) grids, the resolution of the CT scan may prohibit easy identification of individual electrodes in the scan. Thus, to circumvent this issue, we use the locations of the corners of the grid and interpolate between them in evenly spaced intervals depending on the grid dimensions.</p></list-item><list-item><p>To use grid interpolation, first identify the coordinates of the electrode grid's four corners, in channel order (for example, in a 16 x 16, 256-channel grid, corner 1 is electrode 1, corner 2 is electrode 16, corner 3 is electrode 241, and electrode 4 is channel 256). Name this file <monospace>hd_grid_corners.mat</monospace> and place in the elecs directory.</p></list-item><list-item><p>In <monospace>img_pipe</monospace>, call the following:</p><list list-type="simple"><list-item><p><monospace>&#x025e6; patient.interp_grid(nrows</monospace> = <monospace>16, ncols</monospace></p><p>&#x000a0;&#x000a0;&#x000a0;= <monospace>16, grid_basename</monospace> = <monospace>'hd_grid')</monospace></p></list-item></list></list-item><list-item><p>This will create the file <monospace>hd_grid_orig.mat</monospace> in <monospace>elecs/individual_elecs</monospace>, which will then be projected to the surface in the next step.</p></list-item></list></sec><sec><title>Projection of subdural surface electrodes to the pial surface</title><list list-type="bullet"><list-item><p>To project the electrodes to the pial surface, we use the four corner electrodes (Figure <xref ref-type="fig" rid="F8">8A</xref>) of the grid to obtain a set of four vectors that outline the grid. Using these outline vectors, we can obtain a set of four normal vectors, one corresponding to each corner (Figure <xref ref-type="fig" rid="F8">8B</xref>). We then take the mean of these vectors to obtain a mean normal vector, which will be the projection direction for the unprojected interpolated electrode grid. Using this mean normal vector, we then project every electrode in the interpolated grid outwards to the smoothed dural surface of the pial mesh (Figures <xref ref-type="fig" rid="F8">8C,D</xref>). Note that, when projecting an orbitofrontal grid, the dural surface of the cortical mesh without temporal lobe is used to ensure projection to the bottom surface of the orbitofrontal cortex.</p></list-item><list-item><p><monospace>patient.project_electrodes(elecfile_prefix</monospace> = <monospace>'hd_grid')</monospace></p></list-item><list-item><p>To project a grid on the orbitofrontal cortex, use:</p><p><monospace>patient.project_electrodes(elecfile_</monospace></p><p><monospace>prefix</monospace> = <monospace>'OFC_grid', surf_type</monospace> = <monospace>'OFC')</monospace></p></list-item><list-item><p>To visualize these electrodes on the brain, use the <monospace>plot_brain</monospace> method:</p><p><monospace>&#x0003e;&#x0003e;&#x0003e;grid_elecs =patient.get_elecs</monospace></p><p><monospace>(elecfile_prefix='hd_grid')['elecmatrix']</monospace></p><p><monospace>&#x0003e;&#x0003e;&#x0003e;patient.plot_brain(elecs=grid_</monospace></p><p><monospace>elecs)</monospace></p></list-item></list><fig id="F8" position="float"><label>Figure 8</label><caption><p><bold>(A)</bold> The grid's corner electrodes are manually located. We interpolate the locations of the rest of the grid electrodes using these corner coordinates, giving us the electrode grid shown in red. The green arrows are the four normal vectors calculated from the corners, and the black arrow is the mean of those normal vectors and will act as our projection direction. <bold>(B)</bold> Projection of the interpolated grid (red) to the convex hull of the pial surface (blue) using the mean normal vector (black arrow). The final projected electrode grid is shown in blue. <bold>(C)</bold> Axial and <bold>(D)</bold> coronal views of the co-registered CT overlaid on the T1 MRI, showing the location of the electrodes prior to surface projection.</p></caption><graphic xlink:href="fninf-11-00062-g0008"/></fig></sec><sec><title>Creation of the elecs_all.mat file</title><list list-type="bullet"><list-item><p>The <monospace>elecs_all.mat</monospace> file combines the individual device coordinates to represent the electrodes in the recording montage order. <monospace>elecs_all.mat</monospace> contains <monospace>elecmatrix</monospace> and <monospace>eleclabels</monospace>. <monospace>elecmatrix</monospace> contains the x, y, z coordinates of each device, combined in the appropriate montage order. <monospace>eleclabels</monospace> contains device descriptors corresponding to these devices, shortened device ID (e.g. G1) in column 1, long device ID (e.g. L256GridElectrode1) in column 2, and device type (e.g. grid) in column 3. The possible values for &#x0201c;device type&#x0201d; should be &#x02018;grid&#x02019;, &#x02018;strip&#x02019;, or &#x02018;depth&#x02019;. Short and long device ID names should be unique. For an example of what this will look like, see Table <xref ref-type="table" rid="T1">1</xref>.</p></list-item><list-item><p>After creating the.mat files for each electrode device in patient.mark_electrodes(), initialize &#x02018;elecs_all.mat&#x02019; by calling patient.make_elecs_all(), which will prompt the user for the information mentioned above, and automatically create the &#x02018;elecs_all.mat&#x02019; file.</p></list-item></list><table-wrap id="T1" position="float"><label>Table 1</label><caption><p>Example structure of the anatomy variable in elecs_all.mat.</p></caption><table frame="hsides" rules="groups"><thead><tr><th valign="top" align="left" rowspan="1" colspan="1"><bold>Shortened device ID</bold></th><th valign="top" align="left" rowspan="1" colspan="1"><bold>Long device ID</bold></th><th valign="top" align="left" rowspan="1" colspan="1"><bold>Device type</bold></th><th valign="top" align="left" rowspan="1" colspan="1"><bold>Anatomical location</bold></th></tr></thead><tbody><tr><td valign="top" align="left" rowspan="1" colspan="1">G1</td><td valign="top" align="left" rowspan="1" colspan="1">L256GridElectrode1</td><td valign="top" align="left" rowspan="1" colspan="1">grid</td><td valign="top" align="left" rowspan="1" colspan="1">superiortemporal</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">G2</td><td valign="top" align="left" rowspan="1" colspan="1">L256GridElectrode2</td><td valign="top" align="left" rowspan="1" colspan="1">grid</td><td valign="top" align="left" rowspan="1" colspan="1">superiortemporal</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">&#x02026;</td><td valign="top" align="left" rowspan="1" colspan="1">&#x02026;</td><td valign="top" align="left" rowspan="1" colspan="1">&#x02026;</td><td valign="top" align="left" rowspan="1" colspan="1">&#x02026;</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">G256</td><td valign="top" align="left" rowspan="1" colspan="1">L256GridElectrode256</td><td valign="top" align="left" rowspan="1" colspan="1">grid</td><td valign="top" align="left" rowspan="1" colspan="1">rostralmiddlefrontal</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">AD1</td><td valign="top" align="left" rowspan="1" colspan="1">LAmygdalaDepth1</td><td valign="top" align="left" rowspan="1" colspan="1">depth</td><td valign="top" align="left" rowspan="1" colspan="1">Left-hippocampus</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">AD2</td><td valign="top" align="left" rowspan="1" colspan="1">LAmygdalaDepth2</td><td valign="top" align="left" rowspan="1" colspan="1">depth</td><td valign="top" align="left" rowspan="1" colspan="1">Left-hippocampus</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">AD3</td><td valign="top" align="left" rowspan="1" colspan="1">LAmygdalaDepth3</td><td valign="top" align="left" rowspan="1" colspan="1">depth</td><td valign="top" align="left" rowspan="1" colspan="1">Left-amygdala</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">AD4</td><td valign="top" align="left" rowspan="1" colspan="1">LAmygdalaDepth4</td><td valign="top" align="left" rowspan="1" colspan="1">depth</td><td valign="top" align="left" rowspan="1" colspan="1">Left-amygdala</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">AD5</td><td valign="top" align="left" rowspan="1" colspan="1">LAmygdalaDepth5</td><td valign="top" align="left" rowspan="1" colspan="1">depth</td><td valign="top" align="left" rowspan="1" colspan="1">Left-amygdala</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">AD6</td><td valign="top" align="left" rowspan="1" colspan="1">LAmygdalaDepth6</td><td valign="top" align="left" rowspan="1" colspan="1">depth</td><td valign="top" align="left" rowspan="1" colspan="1">Left-amygdala</td></tr></tbody></table></table-wrap></sec></sec><sec><title>Automated anatomical labeling of electrodes</title><list list-type="bullet"><list-item><p>To automatically label the electrodes, call the <monospace>label_elecs()</monospace> method:</p><p><monospace>&#x000bb; patient.label_elecs(elecfile_prefix</monospace></p><p><monospace>='elecs_all', atlas_surf='desikan-</monospace></p><p><monospace>killiany, atlas_depth='destrieux)</monospace></p></list-item><list-item><p>This will add a fourth column to the <monospace>elecs_all.mat</monospace> file that will match labels from the Desikan-Killiany atlas (Desikan et al., <xref rid="B4" ref-type="bibr">2006</xref>) or the Destrieux atlas (Fischl et al., <xref rid="B7" ref-type="bibr">2004</xref>). The Desikan-Killiany atlas is a coarser parcellation that we generally use for surface labeling, whereas the more complex Destrieux atlas is used for labeling depth electrodes.</p></list-item><list-item><p>For surface electrodes, labeling is performed by finding the closest surface vertex (according to Euclidean distance) and determining the Freesurfer label of that point from the annotation file associated with the atlas of interest. For depth electrodes, the label is assigned according to the voxel label in the parcellated volume (<monospace>aparc</monospace>+<monospace>aseg.mgz</monospace>
<monospace>or aparc.a2009s</monospace>+<monospace>aseg.mgz</monospace>).</p></list-item></list><sec><title>Pause point: quality checking anatomical labeling</title><list list-type="bullet"><list-item><p>Quality checking the anatomical labeling is done using the method <monospace>plot_recon_anatomy().</monospace></p><p><monospace>&#x000a0;&#x000bb; patient.plot_recon_anatomy()</monospace></p></list-item><list-item><p>The automatic labeling will sometimes mislabel electrodes that lie on the border between two areas. For example, in Figure <xref ref-type="fig" rid="F9">9A</xref>, an electrode on superior temporal gyrus (label: superiortemporal) is labeled pars triangularis (label: parstriangularis), and an electrode on the caudal middle frontal gyrus is labeled pars opercularis.</p></list-item><list-item><p>To correct an anatomical label, use the <monospace>edit_elecs_all()</monospace> method. The arguments include label names as keys and lists of electrode numbers as values, and the prefix of the electrode file. For example, to correct the two mislabeled electrodes in Figure <xref ref-type="fig" rid="F9">9</xref>, the user would perform the following:</p><list list-type="simple"><list-item><p><monospace>&#x025e6; revision_dict =</monospace></p><p><monospace>&#x000a0;&#x000a0;{'superiortemporal':[246],</monospace></p><p><monospace>'caudalmiddlefrontal:[174]}</monospace></p></list-item><list-item><p><monospace>&#x025e6; patient.edit_elecs_all(revision_dict,</monospace></p><p><monospace>&#x000a0;&#x000a0;elecfile_prefix = 'elecs_all'</monospace>)</p></list-item></list></list-item></list><fig id="F9" position="float"><label>Figure 9</label><caption><p>Surface electrodes are labeled by Freesurfer using the Desikan-Killiany atlas&#x02014;each color represents a different anatomical region. Electrodes are labeled using the anatomical label of the nearest vertex in the brain mesh. <bold>(A)</bold> Anatomical labeling of surface electrodes with errors identified as yellow circles. <bold>(B)</bold> Corrected anatomical labeling.</p></caption><graphic xlink:href="fninf-11-00062-g0009"/></fig></sec></sec><sec><title>Warping surface and depth electrodes to a common atlas</title><p>To warp electrodes from the native space to a common atlas space, call <monospace>patient.warp_all(elecfile_prefix</monospace> = <monospace>'elecs_all')</monospace>, which will by default warp the subject brain to the <monospace>cvs_avg35_inMNI152</monospace> brain, and generate the warped coordinates for both surface and depth electrodes in elecs_all.mat. Options passed into this method may be changed if the user wishes to warp a subset of electrodes, such as only surface or only depth electrodes, or if they wish to use a different template brain.</p><p>The surface warps are generated by projecting the pial surfaces of the subject and template brains into a spherical coordinate space, and aligning the surfaces in that space &#x02013; this is shown in Figures <xref ref-type="fig" rid="F10">10A&#x02013;D</xref>. Depth warping is performed using a combination of volumetric and surface warping (Postelnicu et al., <xref rid="B19" ref-type="bibr">2009</xref>). We have found that surface warping the strip and grids results in more accurate placement of the warped electrodes on the same gyri as in the native space, whereas for depth electrodes a volumetric and surface warping is necessary.</p><fig id="F10" position="float"><label>Figure 10</label><caption><p>Surface warping procedure. <bold>(A)</bold> Electrodes on native brain. Gyri are colored according to anatomical designation by Freesurfer. An example electrode localized to the native STG can be seen circled. Electrodes are warped from the subject's native brain to the cvs_avg35_inMNI152 average brain in spherical surface space. The native lh.sphere is shown in <bold>(B)</bold>, with the location of the same STG electrode marked in red. lh.sphere is shown with curvature and anatomical color coding. Warping occurs when the native lh.sphere is warped to match the lh.sphere for the cvs_avg35_inMNI152 average brain, shown in <bold>(C)</bold>. The same STG electrode is now shown in red on the average brain. Finally, the localization in spherical space is used to localize the electrode on the pial surface of the cvs_avg35_inMNI152 average brain, shown in <bold>(D)</bold>.</p></caption><graphic xlink:href="fninf-11-00062-g0010"/></fig><p>Note that warping depth electrodes takes significantly longer than warping surface electrodes.</p><sec><title>Pause point: quality checking warps</title><list list-type="bullet"><list-item><p><monospace>patient.warp_all()</monospace> will have generated PDFs in the subject's <monospace>elecs</monospace> directory (<sup>*</sup><monospace>_recon_anatomy.pdf</monospace> and <sup>*</sup><monospace>_warped_recon_anatomy.pdf</monospace>) of the electrodes and their warps. To check the warp interactively, use <monospace>patient.plot_recon_anatomy_compare_warped(template</monospace> = <monospace>'cvs_avg35_inMNI152', elecfile_prefix</monospace> = <monospace>TDT_elecs_all)</monospace>.</p></list-item></list></sec><sec><title>Pause point: quality checking depth electrode warping</title><list list-type="bullet"><list-item><p>patient.check_depth_warps() will generate a pdf in the subject's elecs directory, depthWarpsQC.pdf comparing an electrode's original location in the subject brain compared to its warped location in the template brain. Figures <xref ref-type="fig" rid="F11">11A,B</xref> shows an accurate warp, and Figures <xref ref-type="fig" rid="F11">11C,D</xref> shows an inaccurate warp. If an electrode's warped location is inaccurate, either remove the electrode from the warped electrode coordinate matrix, or manually choose the location in the template brain.</p></list-item></list><fig id="F11" position="float"><label>Figure 11</label><caption><p>Examples of accurate depth warp <bold>(A,B)</bold> and inaccurate depth warp <bold>(C,D)</bold>. Colors correspond to anatomical label, and the red circle marks electrode in single subject brain <bold>(A,B)</bold> and the location it is warped to in the CVS brain <bold>(C,D)</bold>. The electrode of interest in <bold>(A)</bold> retains its anatomical label, left hippocampus, when warped to the CVS brain in <bold>(B)</bold>. However, the electrode of interest in <bold>(C)</bold> is incorrectly warped from right hippocampus in the single subject brain to cerebellar cortex in the CVS brain <bold>(D)</bold>.</p></caption><graphic xlink:href="fninf-11-00062-g0011"/></fig></sec></sec><sec><title>Plotting electrodes and activity on the pial surface</title><list list-type="simple"><list-item><p><monospace>patient.plot_recon_anatomy()</monospace> plots anatomically labeled electrodes on the brain.</p></list-item><list-item><p>&#x02022; Warped electrodes can be plotted on a template brain by calling <monospace>patient.plot_recon_anatomy(elecfile_prefix</monospace> = <monospace>'warped_elecs_file'</monospace>, <monospace>template</monospace> = <monospace>your_template)</monospace>.</p></list-item><list-item><p>&#x02022; To plot electrode activity on the brain's surface, use the method <monospace>plot_brain()</monospace>. The user can control the opacity of the brain mesh, wireframe/surface representation, electrode colors, and colormap. For example:</p><list list-type="simple"><list-item><p><monospace>&#x0003e;&#x0003e;&#x0003e; pial = patient.roi('pial', color=</monospace></p><p><monospace>(0.6,0.3,0.6), opacity=0.1, representation</monospace></p><p><monospace>='wireframe', gaussian=True)</monospace></p></list-item><list-item><p>&#x000a0;</p><p><monospace>&#x0003e;&#x0003e;&#x0003e; hipp = patient.roi('lHipp', color=</monospace></p><p><monospace>(0.5,0.1,0.8), opacity = 1.0,</monospace></p><p><monospace>representation='surface', gaussian=True)</monospace></p></list-item><list-item><p>&#x000a0;</p><p><monospace>&#x0003e;&#x0003e;&#x0003e; elecs = patient.get_elecs()</monospace></p><p><monospace>['elecmatrix']</monospace></p></list-item><list-item><p>&#x000a0;</p><p><monospace>&#x0003e;&#x0003e;&#x0003e; patient.plot_brain(rois=[pial,hipp],</monospace></p><p><monospace>elecs=elecs, weights=np.random.uniform</monospace></p><p><monospace>(0,1,(elecs.shape[0])))</monospace></p></list-item></list></list-item><list-item><p>&#x02022; The following code will allow the user to show activity on the superior temporal gyrus as interpolated gaussian blobs (Figure <xref ref-type="fig" rid="F12">12A</xref>):</p><p><monospace>&#x000a0;&#x000a0;&#x0003e;&#x0003e;&#x0003e; elecmatrix = patient.get_elecs(roi =</monospace></p><p><monospace>&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;'superiortemporal') ['elecmatrix']</monospace></p><p><monospace>&#x000a0;&#x000a0;&#x0003e;&#x0003e;&#x0003e; pial = patient.roi('lh_pial',</monospace></p><p><monospace>&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;color=(0.8,0.8,0.8), opacity=0.2,</monospace></p><p><monospace>&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;representation=wireframe,</monospace></p><p><monospace>&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;gaussian=False)</monospace></p><p><monospace>&#x000a0;&#x000a0;&#x0003e;&#x0003e;&#x0003e; patient.make_roi_mesh</monospace></p><p><monospace>&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;('superiortemporal',</monospace></p><p><monospace>&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;label_list=['superiortemporal'])</monospace></p><p><monospace>&#x000a0;&#x000a0;&#x0003e;&#x0003e;&#x0003e; stg_roi = patient.roi</monospace></p><p><monospace>&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;('lh_superiortemporal',</monospace></p><p><monospace>&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;color=(0.3,0.6,0.8), opacity=1.0,</monospace></p><p><monospace>&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;representation='surface',</monospace></p><p><monospace>&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;gaussian=True)</monospace></p><p><monospace>&#x000a0;&#x000a0;&#x0003e;&#x0003e;&#x0003e; patient.plot_brain(rois =</monospace></p><p><monospace>&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;[pial,stg_roi], elecs=elecmatrix,</monospace></p><p><monospace>&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;weights=np.random.uniform(&#x02212;1,0,</monospace></p><p><monospace>&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;elecmatrix.shape[0]), showfig=True,</monospace></p><p><monospace>&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;screenshot=True, cmap='RdBu')</monospace></p><p>Here's another example, plotting regions of interest (ROIs) for the pre- and postcentral gyri as well as electrode activity (Figure <xref ref-type="fig" rid="F12">12B</xref>).</p><p><monospace>&#x000a0;&#x000a0;&#x0003e;&#x0003e;&#x0003e; #get all coordinates of elecs in</monospace></p><p><monospace>&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;precentral+postcentral</monospace></p><p><monospace>&#x000a0;&#x000a0;&#x0003e;&#x0003e;&#x0003e; elecmatrix = np.concatenate</monospace></p><p><monospace>&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;([patient.get_elecs(roi=</monospace></p><p><monospace>&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;'postcentral')['elecmatrix'],</monospace></p><p><monospace>&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;patient.get_elecs(roi ='precentral')</monospace></p><p><monospace>&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;['elecmatrix']],axis=0)</monospace></p><p><monospace>&#x000a0;&#x000a0;&#x0003e;&#x0003e;&#x0003e; #get meshes of precentral,</monospace></p><p><monospace>&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;postcentral gyri, and pial surface</monospace></p><p>&#x000a0;</p><p><monospace>&#x000a0;&#x000a0;&#x0003e;&#x0003e;&#x0003e; patient.make_roi_mesh('precentral',</monospace></p><p><monospace>&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;label_list=['precentral'])</monospace></p><p>&#x000a0;</p><p><monospace>&#x000a0;&#x000a0;&#x0003e;&#x0003e;&#x0003e; patient.make_roi_mesh('postcentral',</monospace></p><p><monospace>&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;label_list=['postcentral'])</monospace></p><p>&#x000a0;</p><p><monospace>&#x000a0;&#x000a0;&#x0003e;&#x0003e;&#x0003e; precentral_roi = patient.roi</monospace></p><p><monospace>&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;('lh_precentral',</monospace></p><p><monospace>&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;color=(0.3,0.6,0.8), opacity=1.0,</monospace></p><p><monospace>&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;representation='wireframe',</monospace></p><p><monospace>&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;gaussian=False)</monospace></p><p>&#x000a0;</p><p><monospace>&#x000a0;&#x000a0;&#x0003e;&#x0003e;&#x0003e; postcentral_roi = patient.roi</monospace></p><p><monospace>&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;('lh_postcentral',</monospace></p><p><monospace>&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;color=(0.5,0.8,0.5), opacity=1.0,</monospace></p><p><monospace>&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;representation='wireframe',</monospace></p><p><monospace>&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;gaussian=False)</monospace></p><p>&#x000a0;</p><p><monospace>&#x000a0;&#x000a0;&#x0003e;&#x0003e;&#x0003e; pial = patient.roi('lh_pial',</monospace></p><p><monospace>&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;(0.8,0.8,0.8),1.0,'surface',False)</monospace></p><p>&#x000a0;</p><p><monospace>&#x000a0;&#x000a0;&#x0003e;&#x0003e;&#x0003e; #calculate distances from two random</monospace></p><p><monospace>&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;electrodes' coordinates.</monospace></p><p>&#x000a0;</p><p><monospace>&#x000a0;&#x000a0;&#x0003e;&#x0003e;&#x0003e; distance1 = np.array</monospace></p><p><monospace>&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;(map(np.linalg.norm, elecmatrix-np.tile</monospace></p><p><monospace>&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;(elecmatrix[30,:], (67,1))))</monospace></p><p>&#x000a0;</p><p><monospace>&#x000a0;&#x000a0;&#x0003e;&#x0003e;&#x0003e; distance2 = np.array</monospace></p><p><monospace>&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;(map(np.linalg.norm, elecmatrix-np.</monospace></p><p><monospace>&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;tile(elecmatrix[20,:], (67,1))))</monospace></p><p>&#x000a0;</p><p><monospace>&#x000a0;&#x000a0;&#x0003e;&#x0003e;&#x0003e; patient.plot_brain</monospace></p><p><monospace>&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;(rois=[pial,sub_roi,sub_roi2],</monospace></p><p><monospace>&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;elecs=elecmatrix,</monospace></p><p><monospace>&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;weights=scipy.stats.zscore</monospace></p><p><monospace>&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;(distance1 + distance2),</monospace></p><p><monospace>&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;showfig=True,</monospace></p><p><monospace>&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;screenshot=True,</monospace></p><p><monospace>&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;cmap='RdPu')</monospace></p></list-item></list><fig id="F12" position="float"><label>Figure 12</label><caption><p>Examples using the plot_brain() function, <bold>(A)</bold> Gaussian representation of electrode weights on a superior temporal gyrus ROI, red-blue color map. <bold>(B)</bold> simulated electrode weights on precentral and postcentral ROIs represented as colored spheres, colored using a red-purple color map.</p></caption><graphic xlink:href="fninf-11-00062-g0012"/></fig></sec><sec><title>Other notes</title><list list-type="bullet"><list-item><p>It is possible to launch specific sub-methods of <monospace>img_pipe</monospace> in separate python sessions. For example, the user may wish to launch <monospace>patient.get_recon()</monospace> 1 day, then open another python session later for <monospace>patient.mark_electrodes()</monospace>. To do this, simply reinitialize the patient according to instructions in section Initializing the Patient in img_pipe, and then continue with the next step.</p></list-item><list-item><p>If the user prefers not to AC-PC orient the images to start (and assuming that this does not affect the quality of the warping step), it is possible to reorient the final surface and electrode.mat files using Freesurfer's talairach.xfm file, which will put them into a common orientation. To do this, the user could perform the following step on the native space electrodes and surface:</p><list list-type="simple"><list-item><p><monospace>&#x025e6; patient.apply_xfm</monospace></p><p><monospace>&#x000a0;(xfm_dir='mri/transforms',</monospace></p><p><monospace>&#x000a0;xfm_file='talairach.xfm',</monospace></p><p><monospace>&#x000a0;source_file='elecs/TDT_elecs_all.mat',</monospace></p><p><monospace>&#x000a0;target_file='elecs/</monospace></p><p><monospace>&#x000a0;TDT_elecs_all_2tal.mat',</monospace></p><p><monospace>&#x000a0;file_type='elecs')</monospace></p></list-item></list><list list-type="simple"><list-item><p><monospace>&#x025e6; patient.apply_xfm</monospace></p><p><monospace>&#x000a0;(xfm_dir='mri/transforms',</monospace></p><p><monospace>&#x000a0;xfm_file='talairach.xfm',</monospace></p><p><monospace>&#x000a0;source_file='Meshes/</monospace></p><p><monospace>&#x000a0;rh_pial_trivert.mat',</monospace></p><p><monospace>&#x000a0;target_file='Meshes/</monospace></p><p><monospace>&#x000a0;rh_pial_trivert_2tal.mat',</monospace></p><p><monospace>&#x000a0;file_type='surf')</monospace></p></list-item></list><list list-type="simple"><list-item><p><monospace>&#x025e6; patient.apply_xfm</monospace></p><p><monospace>&#x000a0;(xfm_dir='mri/transforms',</monospace></p><p><monospace>&#x000a0;xfm_file='talairach.xfm',</monospace></p><p><monospace>&#x000a0;source_file='Meshes/</monospace></p><p><monospace>&#x000a0;lh_pial_trivert.mat',</monospace></p><p><monospace>&#x000a0;target_file='Meshes/</monospace></p><p><monospace>&#x000a0;lh_pial_trivert_2tal.mat',</monospace></p><p><monospace>&#x000a0;file_type='surf')</monospace></p></list-item></list></list-item></list></sec></sec><sec id="s4"><title>Discussion and conclusion</title><p>Here we have described a full pipeline for obtaining high quality 3D surface renderings, labeled, localized electrodes, and atlas-warped electrodes from an input T1 and CT scan. This process has been optimized from start to finish to allow the user to easily create the needed files for later functional analyses. Our software relies on completely free, easily downloadable, open source tools. We also provide plotting tools so that users may easily plot localized electrodes in either the native subject space or a warped subject space.</p><sec><title>Common problems/troubleshooting</title><p>In previous sections we described some pause points for quality checking in between each of the steps in this protocol. However, for convenience we also provide here some potential pitfalls that users may encounter while running this pipeline.</p><sec><title>Installation issues</title><p>Most installation issues can be avoided by following the instructions above and using the conda environment to install the required packages. Using the conda environment avoids potential version conflicts (for example VTK 6.3.0 is required when using Python 2.7, but VTK 7.0.0 is required for Python 3.5. In addition, pyqt version 4 is required rather than the most recent version 5). Be sure that environmental variables are set for <monospace>FREESURFER_HOME</monospace> and <monospace>SUBJECTS_DIR</monospace>, and that paths are set appropriately. Note that Freesurfer does not currently run on Windows, so for users running Windows we suggest running a Linux virtual machine with VirtualBox or other virtualization software.</p><p>If issues are encountered when importing img_pipe despite following the conda environment instructions, the user should attempt the import outside the img_pipe directory. Check that the version imported is located in a directory such as ~<monospace>/anaconda/lib/python2.7/site-packages/img_pipe</monospace>.</p></sec><sec><title>AC-PC alignment issues</title><p>The user may find that aligning scans in Freeview causes part of the volume to be cut off, especially where the image itself must be translated over a large distance (more than a centimeter or two). We have found that this issue is most common with Freeview v1.0, and does not occur with Freeview v2.0.</p></sec><sec><title>Issues with freesurfer reconstruction</title><p>If the freesurfer reconstruction fails or is of poor quality, there are a number of potential reasons. The most common in our experience are (1) poor image contrast due to scanner parameters or due to subject motion, (2) poor image resolution (greater than 1 &#x000d7; 1 &#x000d7; 1 mm voxel size), and (3) images with GAD contrast used in clinical procedures. In all of these cases, the best course of action is to obtain a better scan or see if one is already available. Suggestions for scanning parameters are available on freesurfer's website. However, if no other scans are available, it is usually better to use a high resolution scan with GAD contrast than a low resolution scan without contrast. The surface reconstruction will likely include some defects where the blood vessels interfere with good gray/white matter boundary detection, but the surfaces are usually acceptable, if mediocre. For subjects with large lesions or tumors, manual segmentation may be necessary and is not described here.</p></sec><sec><title>Problems with CT to MRI coregistration</title><p>For appropriate CT to MRI coregistration, the user should select the highest resolution T1 and CT scans, both without contrast. The initial conditions of these two scans may also influence whether good coregistration is achieved. As mentioned previously, if the coregistration step fails, the CT and the T1 scan should first be roughly aligned (this can be done in Freeview, SPM, or other neuroimaging programs), and then coregistration re-attempted. Other parameters that can be adjusted in the coregistration method are the smoothing parameter, interpolation method, and tolerance parameters for function minimization. These parameters are described in the docstring for <monospace>img_pipe.reg_img</monospace>.</p></sec><sec><title>Problems with manual electrode localization</title><p>At times, relatively poor resolution of a CT scan may make it difficult to localize individual electrodes as they tend to blur into one another. In this case, the user may opt to identify the first and last electrodes in a depth electrode, for example, and linearly interpolate between them. This is not currently implemented directly in img_pipe, but can be performed in python with minimal effort.</p><p>Other issues with identifying electrodes can be aided by using the 3D viewer [press &#x02018;3&#x02019; while in <monospace>patient.mark_electrodes()</monospace> mode]. This can help the user to determine whether they are correctly identifying a strip electrode curving around the temporal lobe, or whether they have correctly labeled two depth electrodes that cross one another.</p></sec><sec><title>Problems with electrode projection</title><p>One common problem with electrode projection is that electrodes will be projected to the wrong hemisphere. In this case, the problem is that the hemisphere of implantation was set incorrectly when initializing the patient.</p><p>Another potential problem can occur when projecting electrodes to the bottom surface of the brain (for example, subtemporal electrodes), since the surface may be concave and electrodes may appear to be &#x0201c;off&#x0201d; of the brain. In this case, we suggest using the smoothed dural surface rather than the convex hull for projection. In addition, we provide the option of projecting to an orbitofrontal ROI (with the option <monospace>elecfile_prefix</monospace> = <monospace>'OFC_grid'</monospace>, see section Projection of Subdural Surface Electrodes to the Pial Surface), which can circumvent problems where the temporal lobe interferes with a normal projection.</p></sec><sec><title>Problems with electrode labeling</title><p>Poor electrode labeling is usually a result of poor image quality and thus poor segmentation of the T1 scan by freesurfer. It is best to quality check the results of the pipeline at each step, so that the freesurfer labeled segmentation (aseg.mgz) nicely follows the anatomy of the T1. If this is not the case, you may need to start over with a new T1 scan with better gray/white matter contrast, or if this is not possible, manually correct any labels that were classified incorrectly.</p></sec><sec><title>Problems with electrode warping</title><p>Electrode warping issues may be encountered when using electrodes that have been projected to the convex hull. This is because, prior to warping, electrodes must be snapped to their nearest surface vertex. Sometimes the closest surface vertex ends up moving the electrode to the incorrect gyrus (for example, an STG electrode might end up above the Sylvian Fissure). If this occurs, the best course of action is to create a temporary file with the electrode coordinates, manually correcting the electrode location to the closest surface vertex on the correct gyrus. Then, perform the warp using this input file (change elecfile_prefix to the temporary name).</p></sec><sec><title>Other problems</title><p>Other problems may be encountered if the user incorrectly enters the hemisphere of implantation (patient.hem must be set to &#x0201c;lh&#x0201d; or &#x0201c;rh&#x0201d; if surface grids are used, otherwise if a stereo EEG case with no grids, &#x0201c;stereo&#x0201d; will suffice).</p><p>While this software provides an easy way to perform electrode localization, it is not without the common caveats inherent to all surface ECoG research. In particular, deformation of the brain surface results in a nonlinear warping of the brain's surface (Hermes et al., <xref rid="B10" ref-type="bibr">2010</xref>; Dykstra et al., <xref rid="B6" ref-type="bibr">2012</xref>), which means that even with perfect co-registration of a post-operative CT to a pre-operative MRI, the localization of electrodes must be verified independently with intraoperative photos when possible, and localization should be reconciled with recorded functional properties.</p></sec></sec><sec><title>Future work</title><p>In future work, we hope to incorporate automated identification of surface electrodes to the pipeline. We have found that current algorithms work well for low-density grids (LaPlante et al., <xref rid="B12" ref-type="bibr">2016</xref>), but often fail for grids with 4 mm or less pitch. The failure modes of automated electrode localization packages often result in labor-intensive correction procedures (e.g,. removing false positives, reordering electrodes so they are in the correct montage order). We have found this error correction to be slower than manual electrode identification by an experienced user, thus here we present only manual methods, although ideally the full pipeline would be automated. It is possible that with improvements in electrode detection algorithms, coupled with higher resolution CT scans, a fully automated solution would be possible.</p><p>Despite these limitations, our software is free, flexible, easy to use, and we hope will provide a way for ECoG labs to create automatically labeled and warped electrodes for ease of future analysis.</p></sec></sec><sec id="s5"><title>Author contributions</title><p>LH, DC, ML, and EC conceived of the work; LH, DC, and ML performed analysis; LH and DC wrote the analysis code; all authors contributed to drafting and revising the article and approved of the final version.</p><sec><title>Conflict of interest statement</title><p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p></sec></sec></body><back><ack><p>The authors would like to acknowledge Yulia Oganian for beta testing. Additional thanks goes to Matthew Leonard and Zachary Greenberg for assistance with early code development, and Lilla Zollei for assistance with the depth warping procedure.</p></ack><fn-group><fn fn-type="financial-disclosure"><p><bold>Funding.</bold> This work was supported by grants from the NIH (F32 DC014192-01 Ruth L. Kirschstein postdoctoral fellowship, to LH, and DP2-OD00862 and R01-DC012379 to EC). This work was also funded by the Defense Advanced Research Projects Agency (DARPA) under Cooperative Agreement Number W911NF-14-2-0043, issued by the Army Research Office contracting office in support of DARPA'S SUBNETS program. The views, opinions, and/or findings expressed are those of the author(s) and should not be interpreted as representing the official views or policies of the Department of Defense or the U.S. Government. EC is a New York Stem Cell Foundation-Robertson Investigator. This research was also supported by The New York Stem Cell Foundation, The McKnight Foundation, The Shurl and Kay Curci Foundation, and The William K. Bowes Foundation. We gratefully acknowledge the support of NVIDIA Corporation with the donation of the Tesla K40 GPU used for this research.</p></fn></fn-group><ref-list><title>References</title><ref id="B1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ashburner</surname><given-names>J.</given-names></name><name><surname>Friston</surname><given-names>K. J.</given-names></name></person-group> (<year>1997</year>). <article-title>Spatial transformation of images</article-title>. <source>Hum. Brain Funct</source>. <fpage>43</fpage>&#x02013;<lpage>58</lpage>.</mixed-citation></ref><ref id="B2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chang</surname><given-names>E. F.</given-names></name></person-group> (<year>2015</year>). <article-title>Towards large-scale, human-based, mesoscopic neurotechnologies</article-title>. <source>Neuron</source>
<volume>86</volume>, <fpage>68</fpage>&#x02013;<lpage>78</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuron.2015.03.037</pub-id><?supplied-pmid 25856487?><pub-id pub-id-type="pmid">25856487</pub-id></mixed-citation></ref><ref id="B3"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dalal</surname><given-names>S. S.</given-names></name><name><surname>Edwards</surname><given-names>E.</given-names></name><name><surname>Kirsch</surname><given-names>H. E.</given-names></name><name><surname>Barbaro</surname><given-names>N. M.</given-names></name><name><surname>Knight</surname><given-names>R. T.</given-names></name><name><surname>Nagarajan</surname><given-names>S. S.</given-names></name></person-group> (<year>2008</year>). <article-title>Localization of neurosurgically implanted electrodes via photograph-MRI-radiograph coregistration</article-title>. <source>J. Neurosci. Methods</source>
<volume>174</volume>, <fpage>106</fpage>&#x02013;<lpage>115</lpage>. <pub-id pub-id-type="doi">10.1016/j.jneumeth.2008.06.028</pub-id><?supplied-pmid 18657573?><pub-id pub-id-type="pmid">18657573</pub-id></mixed-citation></ref><ref id="B4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Desikan</surname><given-names>R. S.</given-names></name><name><surname>S&#x000e9;gonne</surname><given-names>F.</given-names></name><name><surname>Fischl</surname><given-names>B.</given-names></name><name><surname>Quinn</surname><given-names>B. T.</given-names></name><name><surname>Dickerson</surname><given-names>B. C.</given-names></name><name><surname>Blacker</surname><given-names>D.</given-names></name><etal/></person-group>. (<year>2006</year>). <article-title>An automated labeling system for subdividing the human cerebral cortex on MRI scans into gyral based regions of interest</article-title>. <source>Neuroimage</source>
<volume>31</volume>, <fpage>968</fpage>&#x02013;<lpage>980</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2006.01.021</pub-id><?supplied-pmid 16530430?><pub-id pub-id-type="pmid">16530430</pub-id></mixed-citation></ref><ref id="B5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dichter</surname><given-names>B. K.</given-names></name><name><surname>Bouchard</surname><given-names>K. E.</given-names></name><name><surname>Chang</surname><given-names>E. F.</given-names></name></person-group> (<year>2016</year>). <article-title>Dynamic structure of neural variability in the cortical representation of speech sounds</article-title>. <source>J. Neurosci.</source>
<volume>36</volume>, <fpage>7453</fpage>&#x02013;<lpage>7463</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.0156-16.2016</pub-id><?supplied-pmid 27413155?><pub-id pub-id-type="pmid">27413155</pub-id></mixed-citation></ref><ref id="B6"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dykstra</surname><given-names>A. R.</given-names></name><name><surname>Chan</surname><given-names>A. M.</given-names></name><name><surname>Quinn</surname><given-names>B. T.</given-names></name><name><surname>Zepeda</surname><given-names>R.</given-names></name><name><surname>Keller</surname><given-names>C. J.</given-names></name><name><surname>Cormier</surname><given-names>J.</given-names></name><etal/></person-group>. (<year>2012</year>). <article-title>Individualized localization and cortical surface-based registration of intracranial electrodes</article-title>. <source>Neuroimage</source>
<volume>59</volume>, <fpage>3563</fpage>&#x02013;<lpage>3570</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2011.11.046</pub-id><?supplied-pmid 22155045?><pub-id pub-id-type="pmid">22155045</pub-id></mixed-citation></ref><ref id="B7"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fischl</surname><given-names>B.</given-names></name><name><surname>Van Der Kouwe</surname><given-names>A.</given-names></name><name><surname>Destrieux</surname><given-names>C.</given-names></name><name><surname>Halgren</surname><given-names>E.</given-names></name><name><surname>S&#x000e9;gonne</surname><given-names>F.</given-names></name><name><surname>Salat</surname><given-names>D. H.</given-names></name><etal/></person-group>. (<year>2004</year>). <article-title>Automatically parcellating the human cerebral cortex</article-title>. <source>Cereb. Cortex</source>
<volume>14</volume>, <fpage>11</fpage>&#x02013;<lpage>22</lpage>. <pub-id pub-id-type="doi">10.1093/cercor/bhg087</pub-id><?supplied-pmid 14654453?><pub-id pub-id-type="pmid">14654453</pub-id></mixed-citation></ref><ref id="B8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Groppe</surname><given-names>D. M.</given-names></name><name><surname>Bickel</surname><given-names>S.</given-names></name><name><surname>Dykstra</surname><given-names>A.</given-names></name><name><surname>Wang</surname><given-names>X.</given-names></name><name><surname>Megevand</surname><given-names>P.</given-names></name><name><surname>Mercier</surname><given-names>M.</given-names></name><etal/></person-group>. (<year>2016</year>). <article-title>iELVis: an open source MATLAB toolbox for localizing and visualizing human intracranial electrode data</article-title>. <source>bioRxiv</source>
<fpage>1</fpage>&#x02013;<lpage>20</lpage>. <pub-id pub-id-type="doi">10.1101/069179</pub-id><?supplied-pmid 28192130?><pub-id pub-id-type="pmid">28192130</pub-id></mixed-citation></ref><ref id="B9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hamilton</surname><given-names>L. S.</given-names></name><name><surname>Edwards</surname><given-names>E.</given-names></name><name><surname>Chang</surname><given-names>E. F.</given-names></name></person-group> (<year>2016</year>). <article-title>Parallel streams define the temporal dynamics of speech processing across human auditory cortex</article-title>. <source>bioRxiv</source>. <pub-id pub-id-type="doi">10.1101/097485</pub-id></mixed-citation></ref><ref id="B10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hermes</surname><given-names>D.</given-names></name><name><surname>Miller</surname><given-names>K. J.</given-names></name><name><surname>Noordmans</surname><given-names>H. J.</given-names></name><name><surname>Vansteensel</surname><given-names>M. J.</given-names></name><name><surname>Ramsey</surname><given-names>N. F.</given-names></name></person-group> (<year>2010</year>). <article-title>Automated electrocorticographic electrode localization on individually rendered brain surfaces</article-title>. <source>J. Neurosci. Methods</source>
<volume>185</volume>, <fpage>293</fpage>&#x02013;<lpage>298</lpage>. <pub-id pub-id-type="doi">10.1016/j.jneumeth.2009.10.005</pub-id><?supplied-pmid 19836416?><pub-id pub-id-type="pmid">19836416</pub-id></mixed-citation></ref><ref id="B11"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kovalev</surname><given-names>D.</given-names></name><name><surname>Spreer</surname><given-names>J.</given-names></name><name><surname>Honegger</surname><given-names>J.</given-names></name><name><surname>Zentner</surname><given-names>J.</given-names></name><name><surname>Schulze-Bonhage</surname><given-names>A.</given-names></name><name><surname>Huppertz</surname><given-names>H.-J.</given-names></name></person-group> (<year>2005</year>). <article-title>Rapid and fully automated visualization of subdural electrodes in the presurgical evaluation of epilepsy patients</article-title>. <source>Am. J. Neuroradiol</source>. <volume>26</volume>, <fpage>1078</fpage>&#x02013;<lpage>1083</lpage>. Available on line at: <ext-link ext-link-type="uri" xlink:href="http://www.ajnr.org/content/26/5/1078/tab-article-info">http://www.ajnr.org/content/26/5/1078/tab-article-info</ext-link><?supplied-pmid 15891163?><pub-id pub-id-type="pmid">15891163</pub-id></mixed-citation></ref><ref id="B12"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>LaPlante</surname><given-names>R. A.</given-names></name><name><surname>Tang</surname><given-names>W.</given-names></name><name><surname>Peled</surname><given-names>N.</given-names></name><name><surname>Vallejo</surname><given-names>D. I.</given-names></name><name><surname>Borzello</surname><given-names>M.</given-names></name><name><surname>Dougherty</surname><given-names>D. D.</given-names></name><etal/></person-group>. (<year>2016</year>). <article-title>The interactive electrode localization utility: software for automatic sorting and labeling of intracranial subdural electrodes</article-title>. <source>Int. J. Comput. Assist. Radiol. Surg</source>. <volume>12</volume>, <fpage>1829</fpage>&#x02013;<lpage>1837</lpage>. <pub-id pub-id-type="doi">10.1007/s11548-016-1504-2</pub-id><?supplied-pmid 27915398?><pub-id pub-id-type="pmid">27915398</pub-id></mixed-citation></ref><ref id="B13"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leonard</surname><given-names>M. K.</given-names></name><name><surname>Baud</surname><given-names>M. O.</given-names></name><name><surname>Sjerps</surname><given-names>M. J.</given-names></name><name><surname>Chang</surname><given-names>E. F.</given-names></name></person-group> (<year>2016</year>). <article-title>Perceptual restoration of masked speech in human cortex</article-title>. <source>Nat. Commun</source>. <volume>7</volume>:<fpage>13619</fpage>. <pub-id pub-id-type="doi">10.1038/ncomms13619</pub-id><?supplied-pmid 27996973?><pub-id pub-id-type="pmid">27996973</pub-id></mixed-citation></ref><ref id="B14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miller</surname><given-names>K. J.</given-names></name><name><surname>Makeig</surname><given-names>S.</given-names></name><name><surname>Hebb</surname><given-names>A. O.</given-names></name><name><surname>Rao</surname><given-names>R. P. N.</given-names></name><name><surname>denNijs</surname><given-names>M.</given-names></name><name><surname>Ojemann</surname><given-names>J. G.</given-names></name></person-group> (<year>2007</year>). <article-title>Cortical electrode localization from X-rays and simple mapping for electrocorticographic research: The &#x0201c;Location on Cortex&#x0201d; (LOC) package for MATLAB</article-title>. <source>J. Neurosci. Methods</source>
<volume>162</volume>, <fpage>303</fpage>&#x02013;<lpage>308</lpage>. <pub-id pub-id-type="doi">10.1016/j.jneumeth.2007.01.019</pub-id><?supplied-pmid 17343918?><pub-id pub-id-type="pmid">17343918</pub-id></mixed-citation></ref><ref id="B15"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moses</surname><given-names>D. A.</given-names></name><name><surname>Mesgarani</surname><given-names>N.</given-names></name><name><surname>Leonard</surname><given-names>M. K.</given-names></name><name><surname>Chang</surname><given-names>E. F.</given-names></name></person-group> (<year>2016</year>). <article-title>Neural speech recognition: continuous phoneme decoding using spatiotemporal representations of human cortical activity</article-title>. <source>J. Neural Eng</source>. <volume>13</volume>, <fpage>1</fpage>&#x02013;<lpage>19</lpage>. <pub-id pub-id-type="doi">10.1088/1741-2560/13/5/056004</pub-id><?supplied-pmid 27484713?><pub-id pub-id-type="pmid">27484713</pub-id></mixed-citation></ref><ref id="B16"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Muller</surname><given-names>L.</given-names></name><name><surname>Felix</surname><given-names>S.</given-names></name><name><surname>Shah</surname><given-names>K. G.</given-names></name><name><surname>Lee</surname><given-names>K.</given-names></name><name><surname>Pannu</surname><given-names>S.</given-names></name><name><surname>Chang</surname><given-names>E. F.</given-names></name></person-group> (<year>2016a</year>). <article-title>Thin-film, high-density micro-electrocorticographic decoding of a human cortical gyrus</article-title>, in <source>IEEE 38th Annual International Conference of the Engineering in Medicine and Biology Society (EMBC)</source> (<publisher-loc>Orlando, FL</publisher-loc>), <fpage>1528</fpage>&#x02013;<lpage>1531</lpage>. <?supplied-pmid 28268617?></mixed-citation></ref><ref id="B17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Muller</surname><given-names>L.</given-names></name><name><surname>Hamilton</surname><given-names>L. S.</given-names></name><name><surname>Edwards</surname><given-names>E.</given-names></name><name><surname>Bouchard</surname><given-names>K. E.</given-names></name><name><surname>Chang</surname><given-names>E. F.</given-names></name></person-group> (<year>2016b</year>). <article-title>Spatial resolution dependence on spectral frequency in human speech cortex electrocorticography</article-title>. <source>J. Neural Eng</source>. <volume>13</volume>:<fpage>56013</fpage>. <pub-id pub-id-type="doi">10.1088/1741-2560/13/5/056013</pub-id><?supplied-pmid 27578414?><pub-id pub-id-type="pmid">27578414</pub-id></mixed-citation></ref><ref id="B18"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oostenveld</surname><given-names>R.</given-names></name><name><surname>Fries</surname><given-names>P.</given-names></name><name><surname>Maris</surname><given-names>E.</given-names></name><name><surname>Schoffelen</surname><given-names>J.-M.</given-names></name></person-group> (<year>2011</year>). <article-title>FieldTrip: open source software for advanced analysis of MEG, EEG, and invasive electrophysiological data</article-title>. <source>Comput. Intell. Neurosci</source>. <volume>2011</volume>:<fpage>156869</fpage>. <pub-id pub-id-type="doi">10.1155/2011/156869</pub-id><?supplied-pmid 21253357?><pub-id pub-id-type="pmid">21253357</pub-id></mixed-citation></ref><ref id="B19"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Postelnicu</surname><given-names>G.</given-names></name><name><surname>Z&#x000f6;llei</surname><given-names>L.</given-names></name><name><surname>Fischl</surname><given-names>B.</given-names></name></person-group> (<year>2009</year>). <article-title>Combined volumetric and surface registration</article-title>. <source>IEEE Trans. Med. Imaging</source>
<volume>28</volume>, <fpage>508</fpage>&#x02013;<lpage>522</lpage>. <pub-id pub-id-type="doi">10.1109/TMI.2008.2004426</pub-id><?supplied-pmid 19273000?><pub-id pub-id-type="pmid">19273000</pub-id></mixed-citation></ref><ref id="B20"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Ramachandran</surname><given-names>P.</given-names></name></person-group> (<year>2001</year>). <article-title>MayaVi: a free tool for CFD data visualization</article-title>, in <source>Annual. CFD Symposium</source> (<publisher-loc>Bangalore</publisher-loc>).</mixed-citation></ref><ref id="B21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tang</surname><given-names>C.</given-names></name><name><surname>Hamilton</surname><given-names>L. S.</given-names></name><name><surname>Chang</surname><given-names>E. F.</given-names></name></person-group> (<year>2017</year>). <article-title>Intonational speech prosody encoding in human auditory cortex</article-title>. <source>Science</source>
<volume>357</volume>, <fpage>797</fpage>&#x02013;<lpage>801</lpage>. <pub-id pub-id-type="doi">10.1126/science.aam8577</pub-id><?supplied-pmid 28839071?><pub-id pub-id-type="pmid">28839071</pub-id></mixed-citation></ref><ref id="B22"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>A. I.</given-names></name><name><surname>Wang</surname><given-names>X.</given-names></name><name><surname>Doyle</surname><given-names>W. K.</given-names></name><name><surname>Halgren</surname><given-names>E.</given-names></name><name><surname>Carlson</surname><given-names>C.</given-names></name><name><surname>Belcher</surname><given-names>T. L.</given-names></name><etal/></person-group>. (<year>2012</year>). <article-title>Localization of dense intracranial electrode arrays using magnetic resonance imaging</article-title>. <source>Neuroimage</source>
<volume>63</volume>, <fpage>157</fpage>&#x02013;<lpage>165</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2012.06.039</pub-id><?supplied-pmid 22759995?><pub-id pub-id-type="pmid">22759995</pub-id></mixed-citation></ref></ref-list></back></article>